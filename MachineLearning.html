<!DOCTYPE html>
<link rel="stylesheet" href="stylepage.css">
<html lang="en"

  
<div>Teachable Machine Image Model - Use an Orange, Banana, Fork or Cell phone to test my Learning Machine, Turn on your Camera!</div>
<script src="https://cdn.jsdelivr.net/npm/p5@latest/lib/p5.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/p5@latest/lib/addons/p5.dom.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/ml5@latest/dist/ml5.min.js"></script>
<script type="text/javascript">
  // Classifier Variable
  let classifier;
  // Model URL
  let imageModelURL = 'https://teachablemachine.withgoogle.com/models/UysZ42x_K/';
  
  // Video
  let video;
  let flippedVideo;
  // To store the classification
  let label = "Nothing";

  // Load the model first
  function preload() {
    classifier = ml5.imageClassifier(imageModelURL + 'model.json');
  }

  function setup() {
    createCanvas(320, 260);
    // Create the video
    video = createCapture(VIDEO);
    video.size(320, 240);
    video.hide();

    flippedVideo = ml5.flipImage(video);
    // Start classifying
    classifyVideo();
  }

  function draw() {
    background(0);
    // Draw the video
    image(flippedVideo, 0, 0);

    // Draw the label
    fill(255);
    textSize(16);
    textAlign(CENTER);
    text(label, width / 2, height - 4);
  }

  // Get a prediction for the current video frame
  function classifyVideo() {
    flippedVideo = ml5.flipImage(video)
    classifier.classify(flippedVideo, gotResult);
    flippedVideo.remove();

  }

  // When we get a result
  function gotResult(error, results) {
    // If there is an error
    if (error) {
      console.error(error);
      return;
    }
    // The results are in an array ordered by confidence.
    // console.log(results[0]);
    label = results[0].label;
    // Classifiy again!
    classifyVideo();
  }
</script>
    
<head>
    <meta charet="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Machine Learning</title>
    
</head>
<body>

<header>
<h1 style="color:blue;">Machine Learning</h1>
</header>
  
  <header>
    <div class="content-wrap">
  <img class="profile-img" src="https://hai.stanford.edu/sites/default/files/styles/person_big/public/2020-03/joy_buolamwini-web_1.jpg?itok=r1raLFQj">
    </div>
  </header>
  
<h3> Embedded video of my algorithm at work</h3>
<h3>Watch my Machine know what I'm showing on screen</h3>
    <a href="https://canvas.wisc.edu/users/32514/external_tools/8273"> Click here to see my Machine At Work</a>
 
 
<h3>Click here to show your own orange, banana, fork or cell phone to see if my Machine Algorithm picks up your sample</h3>
  <p>
<a href="https://teachablemachine.withgoogle.com/models/UysZ42x_K/">Click here and Test my Machine
  </a>
  </p>
<P>   
<a href="https://www.youtube.com/watch?v=kwcillcWOg0">Learn how to Make your own Image Learning Machine</a>
</body>
  </P>
<p>
<a href="https://omny.fm/shows/midday/dr-joy-buolamwini-questions-technology-in-unmaskin"> </a>
</p>

<audio src="https://omny.fm/shows/midday/dr-joy-buolamwini-questions-technology-in-unmaskin"></audio>
  <head>
    <meta charet="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project Statement</title>
   
    <h1>Project Statement</h1>
    
</head>
<style>
.links a {
  text-decoration:none;
}
</style>
<p> As I began to train my Machine on how to identify between an Orange, Banana, Fork and Cell Phone I felt like I was sitting next to Dr. Buolamwini. I felt that she was talking to me and walking me through how to set up the camera then how to begin showing the items I picked to show in my Teachable Machine Image Model. </p>

<p> Then I started thinking how old is my orange, are all my oranges the same or are they slightly different. I wanted to go to the grocery store and pick like 5 different oranges that were all different, some oranges are smaller than others, some oranges have different shapes and some oranges are discolored. For the sake of time, I decided not to go to the grocery store but what if my learning machine wasn’t able to pick up on my lighter discolored orange and thought it was an apple? What if my greener banana was mistaken for a cucumber? What if my Navel Orange was mistaken for a Blood Orange? These ideas began to plague me much like Dr. Buolamwini Black face issue became what it did. Why was the orange recognition not picking up on my discolored Orange? This idea might be something that could be brought up in a class assignment for the future of this class. </p>
<p> I’ve always thought about the Apple I phone and wondered if the facial recognition in the iphone ever made mistakes. I wonder how could Apple got it right but Amazon wasn’t able to do it? In an interview that is posted in this website. Dr. Buolamwini states that when she first bought her first Iphone her mother could open the phone with the facial recognition. She also points out that in China there were two unrelated women who could also open each other’s phones. So, although Apple’s face recognition is good it’s not perfected. </P>
<p> Cameras have to be calibrated right? From the reading I found one thing to really stick out to me and resonate with me. It was when cameras were first coming out and photographs were being printed. The film was made for light skinned people. How bias can you be as a company to only make film for light skinned people. I get it maybe back then dark-skinned people couldn’t afford the camera’s and it didn’t matter as much as it does today but how hard could it have been to just make film for dark toned people. Also, wouldn’t you want the option to take photo in the dark anyway? I can remember camera’s not working in the dark, you would take a photo and it would just be pitch black when you received the photo. But can’t cameras be calibrated? When you go to print wouldn’t you be able to calibrate the photo so you could see something? Was it just a dead end where you wouldn’t be able to see a dark-skinned person in a photo or could you calibrate it to be seen? I personally get worked up about this issue. Now a day’s, people take pictures with there cell phones and are able to use filters to lighten or darken a photo in all sorts of colors and shapes. So, back when photos didn’t work very well on dark skinned people was it the photo film it’s self or both the film and camera? Dr. Buolamwini talks about the Shirley card, Shirley was a model who became the image to calibrate the whole process of camera’s but she was a white woman who was lighter skinned. Then Kodak came out with there new way to calibrate because of the chocolate companies who couldn’t tell the difference between there dark chocolates and the lighter milk chocolates. So, it wasn’t a limitation of the technology it was a limitation of the imagination or the bias mind.</p>
<p> Training A.I. systems was the other point that popped out at me. It was the existing data sets, the overwhelmingly data sets that were pale male data sets that came from Amazon, IBM, Microsoft and Face++. Although companies like Amazon were selling this algorithm it was bias in an extreme way. How could you sell a product that was supposedly able to face recognize all humas when in reality it wasn’t even close to being able to do the job it was meant to do. The American way has been this way for many centuries and it kills me to think that sales man still push products that don’t work well. At the end of the day it really is all greed and how fast I can make a return on my product or invention instead of perfecting the product and standing proudly behind your product.  I recently rewatched the movie Tommy Boy and can remember how important it was for the buyers of Callahan brake pads to see the word “Guarantee” on the box. But like Tommy Boy said he could make a bad brake pad and slap the word guarantee on it and it would still be a bad break pad. What Tommy Boy was getting across to the buyer was that his break pads were quality made and his Callahan name stood behind the break pad, not some crappy break pad that was going to fall apart with the word guarantee stamped on the box.</p>
<p> So, the data sets that Amazon was selling to the FBI where overwhelmingly set up to work on pale males. It brings me to my point of how many innocent dark skinned male and females were incarcerated during those few years that this algorithm was used. Have those cases been thrown out? Have those innocent bystanders been released from jail? It’s as though this algorithm of facial recognition was made to once again target the black community, to keep them down as a race and keep the judicial system and to keep the judicial systme working like it has been for hundreds of years. The percentage of black humans in the prison system is at an all time high and with targeted systems like this it will continue. </p>

  <div class=content-wrap">
<img src="https://umd-today.transforms.svdcdn.com/production/hero/1_JoyinMaskStill_1920x1080.jpg?w=1920&h=1080&auto=compress%2Cformat&fit=crop&dm=1630026049&s=f48378689270e5197d99a97db3590da1">
  
  <a href="https://omny.fm/shows/midday/dr-joy-buolamwini-questions-technology-in-unmaskin">Dr. Buolamwini Podcast Interview.</a>

    
<h1><p style="color:red;">Fight the Bias</p></h1>
    
<header>
    <div class="content-wrap">

        
<h1><p style="color:orange;">Hey A.I.Can you see my face?</p></h1>
      <h3>Dr. Buolamwini Youtube Video</h3>
<div class="contact-info">
<a href="https://www.youtube.com/watch?v=UG_X_7g63rY">Fighting Bias Algorithms.</a>
      
      <div class="content-wrap">
        <img class="profile-img" src="https://npr.brightspotcdn.com/dims4/default/c6854d2/2147483647/strip/true/crop/1600x2000+0+0/resize/1760x2200!/format/webp/quality/90/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2F9e%2Fc2%2F7d9dfb3943bc9df8465427eb9662%2Funmasking-ai-and-dr-joy-b.jpg">
        
</header>
    <div class=content-wrap">
<img src="https://sunnewsaustin.com/wp-content/uploads/2024/03/Buo.jpg">
</div>
</header>


<header>
  <div class="content-wrap">
<img class="profile-img" src="">
      

    
</div>
</header>

</body>
</html>


  <h3>Dr. Buolamwini Youtube Video</h3>
<div class="contact-info">
<a href="https://www.youtube.com/watch?v=UG_X_7g63rY">Fighting Bias Algorithms.</a>

</div>
</section>

<head>
    <meta charet="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
<h2>Now that your camera is turned on, show your camera an orange fruit, a banana, a fork or cell phone to see if my Machine Algorithm picks up your sample on your camera</h2>
</head>
</html>
